{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json \n",
    "import os\n",
    "import io\n",
    "import collections\n",
    "import math\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from pprint import pprint\n",
    "from shutil import copyfile, move\n",
    "\n",
    "import keras_resnet.models\n",
    "\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "#     config.gpu_options.per_process_gpu_memory_fraction = .7\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "keras.backend.tensorflow_backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "as_grey = False\n",
    "batch_size = 32\n",
    "test_batch_size = 32\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation_path_train = 'U:\\PycharmProjects\\AnimalBiometrics\\data\\\\annotations\\\\train_annotations.json'\n",
    "# annotation_path_val = 'U:\\PycharmProjects\\AnimalBiometrics\\data\\\\annotations\\\\val_annotations.json'\n",
    "\n",
    "# load labels\n",
    "# train_dict = {}\n",
    "# train_labels=open(annotation_path_train)\n",
    "# data_train = json.load(train_labels)\n",
    "# for elem in data_train['annotations']:\n",
    "#     train_dict[elem['image_id']] = elem['category_id']\n",
    "\n",
    "# train_labels.close()\n",
    "# training_size = len(train_dict.values())\n",
    "\n",
    "# val_dict = {}\n",
    "# val_labels=open(annotation_path_val)\n",
    "# data_val = json.load(val_labels)\n",
    "# for elem in data_val['annotations']:\n",
    "#     val_dict[elem['image_id']] = elem['category_id']    \n",
    "\n",
    "# val_labels.close()\n",
    "# val_size = len(val_dict.values())\n",
    "\n",
    "# for key, value in train_dict.items():\n",
    "#     copyfile(os.getcwd() + '/data/train_val/{}.jpg'.format(key), os.getcwd() + '/data/train/{}/{}.jpg'.format(value, key))\n",
    "    \n",
    "# for key, value in val_dict.items():\n",
    "#     copyfile(os.getcwd() + '/data/train_val/{}.jpg'.format(key), os.getcwd() + '/data/val/{}/{}.jpg'.format(value, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 408979 images belonging to 87 classes.\n",
      "Found 102288 images belonging to 87 classes.\n"
     ]
    }
   ],
   "source": [
    "# load images with generators\n",
    "\n",
    "# train_path = os.getcwd() + '/data/Clouded_leopard_ID/train_cleaned_cropped'\n",
    "# test_path = os.getcwd() + '/data/Clouded_leopard_ID/test_cleaned_cropped'\n",
    "\n",
    "train_path = 'D://Species//train_cropped'\n",
    "test_path = 'D://Species//test_cropped'\n",
    "\n",
    "\n",
    "images = []\n",
    "\n",
    "# augmentation configuration for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.1,\n",
    "#         zoom_range=0.25,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "\n",
    "# augmentation configuration for testing\n",
    "validation_datagen = ImageDataGenerator(\n",
    "#         rotation_range=90,\n",
    "#         width_shift_range=0.25,\n",
    "#         height_shift_range=0.25,\n",
    "        rescale=1./255,\n",
    "#         shear_range=0.25,\n",
    "#         zoom_range=0.25,\n",
    "#         horizontal_flip=True,\n",
    "#         vertical_flip=True\n",
    ")\n",
    "\n",
    "# train batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# test batches of augmented image data\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "unique, counts = np.unique(train_generator.classes, return_counts=True)\n",
    "\n",
    "n_samples = len(train_generator.filenames)\n",
    "n_classes = len(np.unique(list(train_generator.class_indices.keys())))\n",
    "count_norm = n_samples / (n_classes * counts)\n",
    "class_weights = dict(zip(unique, count_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_pred(pred):\n",
    "#     ids = [file[4:-4] for file in test_generator.filenames]\n",
    "#     df = pd.DataFrame(np.append(ids, pred).reshape(2, len(pred)).T)\n",
    "#     df.columns = ['id','animal_present']\n",
    "#     df.to_csv('./predictions2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import get_file\n",
    "import keras_resnet.models\n",
    "\n",
    "def download_imagenet(depth):\n",
    "    resnet_filename = 'ResNet-{}-model.keras.h5'\n",
    "    resnet_resource = 'https://github.com/fizyr/keras-models/releases/download/v0.0.1/{}'.format(resnet_filename)\n",
    "\n",
    "    filename = resnet_filename.format(depth)\n",
    "    resource = resnet_resource.format(depth)\n",
    "    if depth == 50:\n",
    "        checksum = '3e9f4e4f77bbe2c9bec13b53ee1c2319'\n",
    "    elif depth == 101:\n",
    "        checksum = '05dc86924389e5b401a9ea0348a3213c'\n",
    "    elif depth == 152:\n",
    "        checksum = '6ee11ef2b135592f8031058820bb9e71'\n",
    "\n",
    "    return get_file(\n",
    "        filename,\n",
    "        resource,\n",
    "        cache_subdir='models',\n",
    "        md5_hash=checksum\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 7436/12781 [================>.............] - ETA: 3:27:50 - loss: 5.0804 - acc: 0.0024"
     ]
    }
   ],
   "source": [
    "run_name='inital_class_weights_balanced'\n",
    "date = 'Saturday_9_29_2018'\n",
    "\n",
    "weights = download_imagenet(depth=50)\n",
    "shape = (HEIGHT, WIDTH, 3)\n",
    "\n",
    "training_size = len(train_generator.filenames)\n",
    "validation_size = len(validation_generator.filenames)\n",
    "n_classes = len(np.unique(list(train_generator.class_indices.keys())))\n",
    "\n",
    "# keras_resnet model\n",
    "x = keras.layers.Input(shape)\n",
    "model = keras_resnet.models.ResNet50(x, include_top=True, freeze_bn=False, classes=n_classes)\n",
    "model.load_weights(weights, by_name=True, skip_mismatch=skip_mismatch)\n",
    "\n",
    "\n",
    "# ResNet-50 from keras applications without FC layers (this was used for the currently best model)\n",
    "# resnet_model = keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet',\n",
    "#                                                     input_shape=(WIDTH, HEIGHT, 3), classes=n_classes)\n",
    "\n",
    "# add classification block\n",
    "# x = Flatten(name='flatten')(resnet_model.output)\n",
    "# # x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "# # x = Dense(512, activation='relu', name='fc2')(x)\n",
    "# x = Dense(n_classes, activation='softmax', name='predictions')(x)\n",
    "# model = Model(input=resnet_model.input, output=x)\n",
    "\n",
    "\n",
    "# load exisiting model to continue training\n",
    "# model = keras.models.load_model(os.getcwd() + '/models/cloud_June 18, 2018.hdf5')\n",
    "\n",
    "\n",
    "# set up tensorboard for progress and analysis \n",
    "# writing_grads might not work with some tf versions\n",
    "tensorboard = TensorBoard(log_dir='D:\\\\Species_Graphs/{}_{}'.format(date, run_name), histogram_freq=0,\n",
    "                                          batch_size=batch_size, write_graph=False, write_grads=False,\n",
    "                                          write_images=True)\n",
    "# save model after each epoch\n",
    "root = 'D:\\\\Species_Snapshots/{}_{}'.format(date, run_name)\n",
    "if not os.path.isdir(root):\n",
    "    os.mkdir(root)\n",
    "file_path = root + '/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath=file_path, monitor='val_acc', verbose=1, save_best_only=False)\n",
    "\n",
    "# reduce lr on plateau of val loss\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0)\n",
    "\n",
    "adam = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-10, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "train_steps = math.ceil(training_size / batch_size)\n",
    "val_steps = math.ceil(validation_size / batch_size)\n",
    "\n",
    "# train_steps = 1\n",
    "# val_steps = 1\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=train_steps, epochs=epochs,\n",
    "                    validation_data=validation_generator, validation_steps=val_steps, verbose=1,\n",
    "                              callbacks=[tensorboard, checkpoint, reduce_lr],\n",
    "                              class_weight=class_weights, \n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute with exiting model which had not 29 classes\n",
    "\n",
    "# # input_tensor = Input(shape=(WIDTH, HEIGHT, 3))\n",
    "\n",
    "# # # VGG without FC layers\n",
    "# # # model = keras.applications.vgg16.VGG16(include_top=False, weights=\"imagenet\")\n",
    "# # model = keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet',\n",
    "# #                                      input_tensor=input_tensor, classes=2)\n",
    "# # x = model(input_tensor)\n",
    "\n",
    "# training_size = len(train_generator.filenames) * 10\n",
    "# validation_size = len(validation_generator.filenames) * 10\n",
    "\n",
    "# model = keras.models.load_model(os.getcwd() + '/models/pretrained.h5')\n",
    "# model.layers.pop()\n",
    "# input_layer = model.input\n",
    "# resnet = model.layers[1]\n",
    "# x = resnet(input_layer)\n",
    "# # model.add(Dense(29, activation='softmax', name='predictions'))\n",
    "# # input_tensor = model.input\n",
    "# # x = model.layers[1:-2]\n",
    "\n",
    "# for layer in model.layers[2:-1]:\n",
    "#     x = layer(x)\n",
    "\n",
    "# # Classification block\n",
    "# # x = Flatten(name='flatten')(x)\n",
    "# x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "# x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "# x = Dense(29, activation='softmax', name='predictions')(x)\n",
    "# model = Model(input=input_layer, output=x)\n",
    "# print(model.layers)\n",
    "    \n",
    "# # set up tensorboard for progress and analysis \n",
    "# # tensorboard = TensorBoard(log_dir=os.getcwd()+\"/logs/cloud/{}\".format(datetime.now().strftime(\"%B %d, %Y\")), histogram_freq=0,\n",
    "# #                                           batch_size=batch_size, write_graph=True, write_grads=True,\n",
    "# #                                           write_images=True)\n",
    "\n",
    "# # checkpoint = ModelCheckpoint(filepath='/model_checkpoints/large_dense_fine/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5', \n",
    "# #                              monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# history = model.fit_generator(train_generator, steps_per_epoch=training_size / batch_size, epochs=epochs,\n",
    "#                     validation_data=validation_generator, validation_steps=validation_size / batch_size, verbose=1,\n",
    "# #                               callbacks=[tensorboard, checkpoint]\n",
    "#                              )\n",
    "\n",
    "# model.save(os.getcwd() + '/models/cloud_{}.hdf5'.format(datetime.now().strftime(\"%B %d, %Y\")))\n",
    "# visualize(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model.predict_generator(test_generator, len([name for name in os.listdir(os.getcwd() + '/data/test/all')]) // test_batch_size, verbose=1)\n",
    "# save_pred(pred.argmax(axis=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
